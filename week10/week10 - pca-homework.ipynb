{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 10 - PCA and Dimension Reduction Homework\n",
    "Execute the below code and answer the following questions. __Do NOT commit the csv file!__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "def generate_data():\n",
    "    x, y = make_classification(n_samples=1500, \n",
    "                            n_features = 20,\n",
    "                            n_informative = 8,\n",
    "                            n_redundant = 5,\n",
    "                            n_repeated = 1, \n",
    "                            n_classes = 3,\n",
    "                            weights = (0.5, 0.25, 0.25),\n",
    "                            random_state = 120\n",
    "                            )\n",
    "    colNames = ['var'+str(x) for x in range(20)]\n",
    "    colNames.append('target')\n",
    "\n",
    "    df = pd.DataFrame(np.concatenate((x,y.reshape(-1,1)), axis=1), columns=colNames)\n",
    "    df.to_csv('pca-dataset.csv', index=False)\n",
    "    \n",
    "generate_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var0</th>\n",
       "      <th>var1</th>\n",
       "      <th>var2</th>\n",
       "      <th>var3</th>\n",
       "      <th>var4</th>\n",
       "      <th>var5</th>\n",
       "      <th>var6</th>\n",
       "      <th>var7</th>\n",
       "      <th>var8</th>\n",
       "      <th>var9</th>\n",
       "      <th>...</th>\n",
       "      <th>var11</th>\n",
       "      <th>var12</th>\n",
       "      <th>var13</th>\n",
       "      <th>var14</th>\n",
       "      <th>var15</th>\n",
       "      <th>var16</th>\n",
       "      <th>var17</th>\n",
       "      <th>var18</th>\n",
       "      <th>var19</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-2.882513</td>\n",
       "      <td>-3.272465</td>\n",
       "      <td>-2.520732</td>\n",
       "      <td>-1.987174</td>\n",
       "      <td>-2.073689</td>\n",
       "      <td>-3.272465</td>\n",
       "      <td>-1.237969</td>\n",
       "      <td>1.690547</td>\n",
       "      <td>-0.211314</td>\n",
       "      <td>-5.753190</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.574979</td>\n",
       "      <td>-1.916275</td>\n",
       "      <td>-5.994075</td>\n",
       "      <td>-3.349615</td>\n",
       "      <td>-0.846193</td>\n",
       "      <td>2.491347</td>\n",
       "      <td>1.360958</td>\n",
       "      <td>-2.892522</td>\n",
       "      <td>-1.377561</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.775242</td>\n",
       "      <td>-1.015994</td>\n",
       "      <td>0.005137</td>\n",
       "      <td>0.057274</td>\n",
       "      <td>0.590205</td>\n",
       "      <td>-1.015994</td>\n",
       "      <td>1.350954</td>\n",
       "      <td>-1.493037</td>\n",
       "      <td>-0.862391</td>\n",
       "      <td>-1.986047</td>\n",
       "      <td>...</td>\n",
       "      <td>0.523760</td>\n",
       "      <td>0.399579</td>\n",
       "      <td>0.088600</td>\n",
       "      <td>0.718606</td>\n",
       "      <td>-1.112030</td>\n",
       "      <td>0.083929</td>\n",
       "      <td>0.606544</td>\n",
       "      <td>-1.376793</td>\n",
       "      <td>1.302641</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.876376</td>\n",
       "      <td>0.220453</td>\n",
       "      <td>3.114224</td>\n",
       "      <td>-1.640025</td>\n",
       "      <td>1.180348</td>\n",
       "      <td>0.220453</td>\n",
       "      <td>0.465102</td>\n",
       "      <td>0.222511</td>\n",
       "      <td>0.880455</td>\n",
       "      <td>2.922315</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.370516</td>\n",
       "      <td>3.585262</td>\n",
       "      <td>-2.168162</td>\n",
       "      <td>2.693429</td>\n",
       "      <td>-0.966636</td>\n",
       "      <td>1.586302</td>\n",
       "      <td>-2.821546</td>\n",
       "      <td>0.482164</td>\n",
       "      <td>0.187404</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-2.550342</td>\n",
       "      <td>-1.968144</td>\n",
       "      <td>0.077681</td>\n",
       "      <td>-1.887719</td>\n",
       "      <td>1.864445</td>\n",
       "      <td>-1.968144</td>\n",
       "      <td>-0.527958</td>\n",
       "      <td>-0.201467</td>\n",
       "      <td>-0.532649</td>\n",
       "      <td>2.287445</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.041341</td>\n",
       "      <td>2.383582</td>\n",
       "      <td>-0.417253</td>\n",
       "      <td>1.305379</td>\n",
       "      <td>-0.435123</td>\n",
       "      <td>-0.468557</td>\n",
       "      <td>0.923290</td>\n",
       "      <td>3.880050</td>\n",
       "      <td>2.676798</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.454974</td>\n",
       "      <td>1.293300</td>\n",
       "      <td>0.112201</td>\n",
       "      <td>-0.589989</td>\n",
       "      <td>-1.674321</td>\n",
       "      <td>1.293300</td>\n",
       "      <td>0.487302</td>\n",
       "      <td>1.776318</td>\n",
       "      <td>0.702520</td>\n",
       "      <td>-1.024127</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.452869</td>\n",
       "      <td>-0.667306</td>\n",
       "      <td>0.345364</td>\n",
       "      <td>-3.920591</td>\n",
       "      <td>-0.438296</td>\n",
       "      <td>-1.690141</td>\n",
       "      <td>0.176906</td>\n",
       "      <td>1.920142</td>\n",
       "      <td>1.474634</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       var0      var1      var2      var3      var4      var5      var6  \\\n",
       "0 -2.882513 -3.272465 -2.520732 -1.987174 -2.073689 -3.272465 -1.237969   \n",
       "1  0.775242 -1.015994  0.005137  0.057274  0.590205 -1.015994  1.350954   \n",
       "2 -0.876376  0.220453  3.114224 -1.640025  1.180348  0.220453  0.465102   \n",
       "3 -2.550342 -1.968144  0.077681 -1.887719  1.864445 -1.968144 -0.527958   \n",
       "4 -0.454974  1.293300  0.112201 -0.589989 -1.674321  1.293300  0.487302   \n",
       "\n",
       "       var7      var8      var9  ...     var11     var12     var13     var14  \\\n",
       "0  1.690547 -0.211314 -5.753190  ... -0.574979 -1.916275 -5.994075 -3.349615   \n",
       "1 -1.493037 -0.862391 -1.986047  ...  0.523760  0.399579  0.088600  0.718606   \n",
       "2  0.222511  0.880455  2.922315  ... -0.370516  3.585262 -2.168162  2.693429   \n",
       "3 -0.201467 -0.532649  2.287445  ... -0.041341  2.383582 -0.417253  1.305379   \n",
       "4  1.776318  0.702520 -1.024127  ... -0.452869 -0.667306  0.345364 -3.920591   \n",
       "\n",
       "      var15     var16     var17     var18     var19  target  \n",
       "0 -0.846193  2.491347  1.360958 -2.892522 -1.377561     0.0  \n",
       "1 -1.112030  0.083929  0.606544 -1.376793  1.302641     2.0  \n",
       "2 -0.966636  1.586302 -2.821546  0.482164  0.187404     0.0  \n",
       "3 -0.435123 -0.468557  0.923290  3.880050  2.676798     1.0  \n",
       "4 -0.438296 -1.690141  0.176906  1.920142  1.474634     0.0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('pca-dataset.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1500 entries, 0 to 1499\n",
      "Data columns (total 21 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   var0    1500 non-null   float64\n",
      " 1   var1    1500 non-null   float64\n",
      " 2   var2    1500 non-null   float64\n",
      " 3   var3    1500 non-null   float64\n",
      " 4   var4    1500 non-null   float64\n",
      " 5   var5    1500 non-null   float64\n",
      " 6   var6    1500 non-null   float64\n",
      " 7   var7    1500 non-null   float64\n",
      " 8   var8    1500 non-null   float64\n",
      " 9   var9    1500 non-null   float64\n",
      " 10  var10   1500 non-null   float64\n",
      " 11  var11   1500 non-null   float64\n",
      " 12  var12   1500 non-null   float64\n",
      " 13  var13   1500 non-null   float64\n",
      " 14  var14   1500 non-null   float64\n",
      " 15  var15   1500 non-null   float64\n",
      " 16  var16   1500 non-null   float64\n",
      " 17  var17   1500 non-null   float64\n",
      " 18  var18   1500 non-null   float64\n",
      " 19  var19   1500 non-null   float64\n",
      " 20  target  1500 non-null   float64\n",
      "dtypes: float64(21)\n",
      "memory usage: 246.2 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 1,200\n",
      "Test samples: 300\n",
      "\n",
      "Features:\n",
      "var0\tvar1\tvar2\tvar3\tvar4\tvar5\tvar6\tvar7\tvar8\tvar9\tvar10\tvar11\tvar12\tvar13\tvar14\tvar15\tvar16\tvar17\tvar18\tvar19\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df[[x for x in df.columns if x.startswith('var')]]\n",
    "y = df['target']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)\n",
    "\n",
    "print(f'Training samples: {X_train.shape[0]:,}')\n",
    "print(f'Test samples: {X_test.shape[0]:,}')\n",
    "\n",
    "print('\\nFeatures:')\n",
    "print(*X_train, sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Description\n",
    "- `var1 - var19`: a feature for the data.  \n",
    "- `target`: variable we wish to be able to predict, which is 1 of 3 classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1\n",
    "- Use principle components analysis to determine the number of components to reduce the data to by evaluating the explained variance ratio (use `X_train`).  \n",
    "- Remember to scale the data first.  \n",
    "- What number of components would you recommend based on your analysis?  \n",
    "- Explain your results using markdown cells."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### calculating components from eigenvalues and vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/numpy/core/_asarray.py:83: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  return array(a, dtype, copy=False, order=order)\n",
      "/opt/anaconda3/lib/python3.8/site-packages/numpy/core/_asarray.py:83: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  return array(a, dtype, copy=False, order=order)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEGCAYAAABo25JHAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAZmklEQVR4nO3de7hc873H8fdHcFSJW1KNoHEJuinBlpZe3KpN9JJSrdtTl9LIqXtPi56euhw9fYqjF4o8qTrog6hWK0iLx/1UQ4IQCSFSly0p0SKKInzPH2ttZzKZmb32Za2Z2evzep55ZtZavzXru9dM5pvf+q3f76eIwMzMymulZgdgZmbN5URgZlZyTgRmZiXnRGBmVnJOBGZmJbdyswPorWHDhsWoUaOaHYaZWVu5//77X4yI4bW2tV0iGDVqFLNmzWp2GGZmbUXS0/W2+dKQmVnJORGYmZWcE4GZWck5EZiZlZwTgZlZyTkRmJmVXG6JQNIlkl6Q9Eid7ZJ0nqQFkh6WtENesZiZWX151gguBcY12D4eGJ0+JgIX5RiLmZnVkVuHsoi4S9KoBkUmAJdHMiHCDElrSxoREYvzisnMVnTlvc9w3eznmh2GVejYYCinfWHrwo7XzDaCkcCzFctd6boVSJooaZakWUuWLCkkOLOyuG72c8xbvLTZYVgTNXOICdVYV3O6tIiYAkwB6Ozs9JRqZgOsY8RQrj5q52aHYU3SzBpBF7BRxfKGwKImxWJmVlrNTATTgEPSu4c+Brzi9gEzs+LldmlI0lXAbsAwSV3AacAqABExGZgO7A0sAF4HDs8rFrPBrL+NvfMWL6VjxNABjMjaTZ53DR3Yw/YAjs7r+GZl0d3Y29cf844RQ5kwpuZ9GlYSbTcfgZmtyI291h8eYsLMrOScCMzMSs6JwMys5JwIzMxKzonAzKzknAjMzErOt4+atYD+dApzhzDrL9cIzFpAf0YAdYcw6y/XCMxahDuFWbO4RmBmVnJOBGZmJedEYGZWck4EZmYl50RgZlZyTgRmZiXn20fNBog7hVm7co3AbIC4U5i1K9cIzAaQO4VZO3KNwMys5JwIzMxKzonAzKzknAjMzErOicDMrOScCMzMSs6JwMys5NyPwCzVn57B4N7B1r5cIzBL9adnMLh3sLUv1wjMKrhnsJWRawRmZiXnRGBmVnJOBGZmJZdrIpA0TtJ8SQsknVJj+1qSrpf0kKS5kg7PMx4zM1tRbolA0hDgAmA80AEcKKmjqtjRwLyI2A7YDThX0qp5xWRmZivKs0YwFlgQEQsj4i1gKjChqkwAa0oSsAbwd2BZjjGZmVmVPBPBSODZiuWudF2lnwMfBhYBc4DjI+Ld6jeSNFHSLEmzlixZkle8ZmallGc/AtVYF1XLnwVmA3sAmwG3SLo7Ipbr1RMRU4ApAJ2dndXvYfYezxts1nt51gi6gI0qljck+Z9/pcOBayOxAPgLsFWOMdkg53mDzXovzxrBTGC0pE2A54ADgIOqyjwD7AncLWl9YEtgYY4xWQm4d7BZ7+SWCCJimaRjgJuAIcAlETFX0qR0+2TgTOBSSXNILiWdHBEv5hWTmZmtKNexhiJiOjC9at3kiteLgM/kGYOZmTXmnsVmZiXnRGBmVnJOBGZmJedEYGZWck4EZmYll/muIUnvj4jX8gzGzPMGmxWvxxqBpF0kzQMeTZe3k3Rh7pFZKXneYLPiZakR/IRkTKBpABHxkKRP5RqVlZp7BpsVK1MbQUQ8W7XqnRxiMTOzJshSI3hW0i5ApJPGHEd6mcjMzNpflhrBJJKZxEaSjCg6Jl02M7NBoMcaQToI3MEFxGJmZk2Q5a6hyyStXbG8jqRLco3KzMwKk+XS0LYR8XL3QkS8BGyfW0RmZlaoLIlgJUnrdC9IWpech682M7PiZPlBPxe4R9Jv0uWvAP+VX0hmZlakLI3Fl0u6H9idZBaxfSNiXu6RWdvyBPJm7SXrJZ7HgJe6y0vaOCKeyS0qa2vdw0T05QfdQ0SYFa/HRCDpWOA04HmSHsUCAtg239CsnXmYCLP2kaVGcDywZUT8Le9gzMyseFnuGnoWeCXvQMzMrDmy1AgWAndIuhF4s3tlRPw4t6jMzKwwWRLBM+lj1fRhZmaDSJbbR88oIhAzM2uOLHcNDQdOArYGVuteHxF75BiXmZkVJEtj8RUk/Qg2Ac4AngJm5hiTmZkVKEsiWC8ifgm8HRF3RsTXgY/lHJeZmRUkS2Px2+nzYkmfAxYBG+YXkrUCDxNhVh5ZEsEPJK0F/BtwPjAUODHXqKzpPEyEWXlkuWvohvTlKyQDz1lJeJgIs3KomwgknRQRZ0s6n2RsoeVExHG5RmZmZoVoVCN4NH2eVUQgZmbWHHUTQURcL2kIsE1EfKcvby5pHPAzYAhwcUT8qEaZ3YCfAqsAL0bErn05lpmZ9U3DNoKIeEfSjn154zSJXADsBXQBMyVNq5zURtLawIXAuIh4RtIH+nIsMzPruyx3DT0oaRpwDfBa98qIuLaH/cYCCyJiIYCkqcAEoHJ2s4OAa7snuYmIF3oRu5mZDYAsiWBd4G9A5ZASAfSUCEaSDGHdrQv4aFWZLYBVJN0BrAn8LCIuzxCTmZkNkCy3jx7ex/dWrbercfwdgT2B9wF/ljQjIh5f7o2kicBEgI033riP4ZiZWS1ZBp1bDTiCFQed+3oPu3YBG1Usb0jSK7m6zIsR8RrwmqS7gO2A5RJBREwBpgB0dnaucCurmZn1XZaxhn4FfBD4LHAnyQ/6qxn2mwmMlrSJpFWBA4BpVWWuAz4paWVJq5NcOnoUMzMrTJZEsHlEfB94LSIuAz4HfKSnnSJiGXAMcBPJj/uvI2KupEmSJqVlHgX+CDwM3Edyi+kjfftTzMysL3oz6NzLkrYB/gqMyvLmETEdmF61bnLV8jnAOVnez7Lrz6Bx4IHjzMokS41giqR1gO+TXNqZB5yVa1TWb92DxvWVB44zK49GYw3NI5mUZmpEvETSPrBpUYFZ/3nQODPLolGN4EBgDeBmSfdKOkHSiILiMjOzgtRNBBHxUER8NyI2A44HPgTcK+k2Sd8oLEIzM8tVljYCImJGRJwIHAKsA/w816jMzKwwWTqU7URymejLJBPXTyEZd8jMzAaBRo3FPwT2B14CpgIfj4iuogIzM7NiNKoRvAmMrx73x8zMBpdGE9OcUWQgZmbWHJkai83MbPByIjAzK7lGjcU7NNoxIh4Y+HDMzKxojRqLz02fVwM6gYdIJpvZFrgX+ES+oZmZWREa9SzePSJ2B54GdoiIzojYEdgeWFBUgGZmlq8sw1BvFRFzuhci4hFJY/ILybr1ZyhpDyNtZlllaSx+VNLFknaTtKukX+BZxArRn6GkPYy0mWWVpUZwOPCvJAPPAdwFXJRbRLYcDyVtZnnrMRFExD8lTQamR8T8AmIyM7MC9XhpSNIXgdkkcwsjaYyk6knozcysTWVpIzgNGAu8DBARs8k4Z7GZmbW+LIlgWUS8knskZmbWFFkaix+RdBAwRNJo4DjgnnzDMjOzomSpERwLbE0yLPVVwFLghBxjMjOzAmW5a+h14Hvpw8zMBpksU1VuAXybpIH4vfIRsUd+YZmZWVGytBFcA0wGLgbeyTccMzMrWpZEsCwi3JPYzGyQytJYfL2kb0oaIWnd7kfukZmZWSGy1AgOTZ+/U7EugE0HPhwzMytalruGNikiEDMza45GU1XuERG3Sdq31vaIuDa/sMzMrCiNagS7ArcBX6ixLQAnAjOzQaBuIoiI09Lnw4sLZ/DxLGNm1uqy3DWEpM9JOknSqd2PjPuNkzRf0gJJpzQot5OkdyTtlzXwduFZxsys1WXpWTwZWB3YnaRT2X7AfRn2GwJcAOwFdAEzJU2LiHk1yp0F3NTr6NuEZxkzs1aWpUawS0QcArwUEWcAOwMbZdhvLLAgIhZGxFvAVGBCjXLHAr8FXsgYs5mZDaAsieCN9Pl1SRsAbwNZbikdCTxbsdyVrnuPpJHAPiRDWNQlaaKkWZJmLVmyJMOhzcwsqyyJ4AZJawPnAA8AT5H8774nqrEuqpZ/CpwcEQ3HMIqIKRHRGRGdw4cPz3BoMzPLKkuHsjPTl7+VdAOwWsYZy7pY/hLShsCiqjKdwFRJAMOAvSUti4jfZ3h/MzMbAI06lNXsSJZuy9KhbCYwWtImwHPAAcBBlQUqey1LuhS4wUnAzKxYjWoEtTqSdeuxQ1lELJN0DMndQEOASyJirqRJ6faG7QJmZlaMRh3K+t2RLCKmA9Or1tVMABFxWH+PZ2ZmvddjY7Gk9SSdJ+kBSfdL+pmk9YoIzszM8pflrqGpwBLgyySdyZYAV+cZlJmZFSfLfATrVtw5BPADSV/KKR4zMytYlhrB7ZIOkLRS+vgqcGPegZmZWTGyJIKjgCuBN9PHVOBbkl6V1LfR1MzMrGVk6VC2ZhGBmJlZc2S5a+iIquUhkk7LLyQzMytSlktDe0qaLmmEpI8AMwDXEszMBoksl4YOkrQ/MAd4HTgwIv6Ue2RmZlaILJeGRgPHk8wZ8BTwNUmr5xyXmZkVJMuloeuB70fEUSQT2j9BMqCcmZkNAlk6lI2NiKUAERHAuZKm5RuWmZkVpdEw1CdFxNkRsVTSVyLimorNhwP/nn94zXflvc9w3ezn+rz/vMVL6RgxdAAjMjMbWI0uDR1Q8fq7VdvG5RBLS7pu9nPMW9z3fnMdI4YyYczInguamTVJo0tDqvO61vKg1jFiKFcftXOzwzAzy0WjGkHUeV1r2czM2lSjGsF26VhCAt5XMa6QgNVyj8zMzArRaIayIUUGYmZmzZGlH4GZmQ1iTgRmZiXnRGBmVnJOBGZmJedEYGZWck4EZmYl50RgZlZyTgRmZiXnRGBmVnJOBGZmJedEYGZWck4EZmYl50RgZlZyTgRmZiWXayKQNE7SfEkLJJ1SY/vBkh5OH/dI2i7PeMzMbEW5JQJJQ4ALgPFAB3CgpI6qYn8Bdo2IbYEzgSl5xWNmZrXlWSMYCyyIiIUR8RYwFZhQWSAi7omIl9LFGcCGOcZjZmY15JkIRgLPVix3pevqOQL4Q60NkiZKmiVp1pIlSwYwRDMzyzMRqMa6mpPeS9qdJBGcXGt7REyJiM6I6Bw+fPgAhmhmZo0mr++vLmCjiuUNgUXVhSRtC1wMjI+Iv+UYj5mZ1ZBnjWAmMFrSJpJWBQ4AplUWkLQxcC3wtYh4PMdYzMysjtxqBBGxTNIxwE3AEOCSiJgraVK6fTJwKrAecKEkgGUR0ZlXTPWccf1c5i1aWnPbvMVL6RgxtOCIzMyKk+elISJiOjC9at3kitdHAkfmGUOln9xSu9Lx4DMvs+TVN2tu6xgxlAljGrVxm5m1t1wTQbvYdYv6DdAn7rVFgZGYmRXPQ0yYmZWcE4GZWck5EZiZlZwTgZlZyTkRmJmVnBOBmVnJORGYmZWcE4GZWcm5Q1kv1OuZXI87o5lZO3CNwMys5JwIzMxKzonAzKzknAjMzErOjcUFcUOzmbUq1wjMzErOicDMrOR8aahN+NKSmeXFNQIzs5JzIjAzKzknAjOzknMbQQm4fcHMGnGNwMys5FwjsIZ6W5sA1yjM2o0TgeXKl6XMWp8TgbWs/iQR12TMsnMiMKuhyCTkBGTN5kRg1mKchKxovmvIzKzknAjMzErOl4bMDHADe5m5RmBmVnJOBGZmJZdrIpA0TtJ8SQsknVJjuySdl25/WNIOecZjZmYryi0RSBoCXACMBzqAAyV1VBUbD4xOHxOBi/KKx8zMasuzRjAWWBARCyPiLWAqMKGqzATg8kjMANaWNCLHmMzMrIoiIp83lvYDxkXEkeny14CPRsQxFWVuAH4UEf+bLt8KnBwRs6reayJJjQFgS2B+jUMOA14c8D9kYLRqbI6r91o1tlaNC1o3tlaNC/KJ7UMRMbzWhjxvH1WNddVZJ0sZImIKMKXhwaRZEdGZPbzitGpsjqv3WjW2Vo0LWje2Vo0Lio8tz0tDXcBGFcsbAov6UMbMzHKUZyKYCYyWtImkVYEDgGlVZaYBh6R3D30MeCUiFucYk5mZVcnt0lBELJN0DHATMAS4JCLmSpqUbp8MTAf2BhYArwOH9+OQDS8dNVmrxua4eq9VY2vVuKB1Y2vVuKDg2HJrLDYzs/bgnsVmZiXnRGBmVnJtlwhacdgKSRtJul3So5LmSjq+RpndJL0iaXb6ODXvuCqO/ZSkOelxZ9XY3oxztmXFuZgtaamkE6rKFHbOJF0i6QVJj1SsW1fSLZKeSJ/XqbNvw+9kDnGdI+mx9LP6naS16+zb8HPPKbbTJT1X8ZntXWffos/Z1RUxPSVpdp19cztn9X4nWuF7RkS0zYOk0flJYFNgVeAhoKOqzN7AH0j6KHwMuLeAuEYAO6Sv1wQerxHXbsANTTpvTwHDGmwv/JzV+Fz/StLhpSnnDPgUsAPwSMW6s4FT0tenAGfVib3hdzKHuD4DrJy+PqtWXFk+95xiOx34dobPu9BzVrX9XODUos9Zvd+JVvietVuNoCWHrYiIxRHxQPr6VeBRYGSexxxgzR7qY0/gyYh4usBjLici7gL+XrV6AnBZ+voy4Es1ds3ynRzQuCLi5ohYli7OIOl/U7g65yyLws9ZN0kCvgpcNVDHy6rB70TTv2ftlghGAs9WLHex4g9uljK5kTQK2B64t8bmnSU9JOkPkrYuKiaS3to3S7pfyXAd1Zp6zkj6mNT7h9mscwawfqT9WtLnD9Qo0+xz93WS2lwtPX3ueTkmvWx1SZ3LHM08Z58Eno+IJ+psL+ScVf1ONP171m6JYMCGrciDpDWA3wInRMTSqs0PkFz62A44H/h9ETGlPh4RO5CM9nq0pE9VbW/mOVsV+CJwTY3NzTxnWTXz3H0PWAZcUadIT597Hi4CNgPGAItJLsNUa9o5Aw6kcW0g93PWw+9E3d1qrBuwc9ZuiaBlh62QtArJh3tFRFxbvT0ilkbEP9LX04FVJA3LO670eIvS5xeA35FUMys1c6iP8cADEfF89YZmnrPU892XyNLnF2qUadb37VDg88DBkV5Erpbhcx9wEfF8RLwTEe8Cv6hzzGads5WBfYGr65XJ+5zV+Z1o+ves3RJBSw5bkV53/CXwaET8uE6ZD6blkDSW5Nz/Lc+40mO9X9Ka3a9JGhofqSrWzKE+6v4PrVnnrMI04ND09aHAdTXKZPlODihJ44CTgS9GxOt1ymT53POIrbJtaZ86xyz8nKU+DTwWEV21NuZ9zhr8TjT/e5ZH63ieD5I7XB4naUH/XrpuEjApfS2SCXGeBOYAnQXE9AmSatrDwOz0sXdVXMcAc0la+2cAuxR0vjZNj/lQevyWOGfpcVcn+WFfq2JdU84ZSTJaDLxN8r+vI4D1gFuBJ9LnddOyGwDTG30nc45rAcn14u7v2uTquOp97gXE9qv0O/QwyQ/ViFY4Z+n6S7u/WxVlCztnDX4nmv498xATZmYl126XhszMbIA5EZiZlZwTgZlZyTkRmJmVnBOBmVnJORFY00l6Jx3t8RFJ10havU65e/r4/p2SzutHfP+os/6DkqZKelLSPEnTJW3R1+O0AiUjvu7S7DisWE4E1greiIgxEbEN8BZJX4L3SBoCEBF9+oGKiFkRcVz/w1wuJpH0PL0jIjaLiA7g34H1B/I4TbAb4ERQMk4E1mruBjZP/2d6u6QrSToovfc/83TbHZJ+o2Rc/isqeiDvJOmedKC6+yStmZa/Id1+uqRfSbpNyfjv30jXryHpVkkPKBmPvqeRHXcH3o5k7m0AImJ2RNyd9tA+J63hzJG0f0Xcd0r6taTHJf1I0sFpnHMkbZaWu1TSZEl3p+U+n65fTdL/pGUflLR7uv4wSddK+mP6N53dHZOkz0j6c/p3XaNknJvucffPqPh7t1IyENok4MS0hvbJfn6W1iZym7zerLeUjAUzHvhjumossE1E/KVG8e2BrUnGW/kT8HFJ95GMI7N/RMyUNBR4o8a+25LMu/B+4EFJN5KM77JPRCxVMp7RDEnTon6Py22A++ts25dk0LXtgGHATEl3pdu2Az5MMkzyQuDiiBirZJKSY4ET0nKjgF1JBnC7XdLmwNEAEfERSVuRjJLZfSlqTHpO3gTmSzo//dv/A/h0RLwm6WTgW8B/pvu8GBE7SPomyRwCR0qaDPwjIv67zt9mg5ATgbWC9+n/Z4y6m2Q8ll2A++okAdJtXQDpvqOAV4DFETETkkHr0u3V+14XEW8Ab0i6nSTh3Aj8UMlok++SDPG7PsmEOb31CeCqiHiHZECxO4GdgKXAzEjHcZL0JHBzus8cklpGt19HMnDbE5IWAlul73t++rc9JulpoDsR3BoRr6TvOw/4ELA2ycQnf0rPwarAnyuO0T3o2f0kyctKyonAWsEbETGmckX6w/Vag33erHj9Dsl3WWQbmre6TAAHA8OBHSPibUlPAas1eI+5wH51ttUaMrhbZdzvViy/y/L/HmvFmPV9K8/HLRFxYA/7dJe3knIbgQ0mjwEbSNoJIG0fqPUDNyG93r4eSePoTGAt4IU0CexO8j/qRm4D/qW7jSE93k6SdgXuAvaXNETScJKpE+/r5d/yFUkrpe0GmwLz0/c9OD3WFsDG6fp6ZpBcMts83Wf1DHc1vUoyjaKViBOBDRqRTOG3P3C+pIeAW6j9v/r7SC4FzQDOjGQM+iuATiUTlh9MklQaHStIhlneS8nto3NJ5utdRHI30cMko1jeBpwUEb29xDQfuJNk9rFJEfFP4EJgiKQ5JG0hh0XEm/XeICKWAIcBV0l6OP17t+rhuNcD+7ixuFw8+qiViqTTafHGUEmXAjdExG+aHYuVg2sEZmYl5xqBmVnJuUZgZlZyTgRmZiXnRGBmVnJOBGZmJedEYGZWcv8H0vohVKtAKFQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Standardize the features using StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train_std = sc.fit_transform(X_train)\n",
    "X_test_std = sc.transform(X_test)\n",
    "\n",
    "# Calculate the covariance matrix for the standardized training data\n",
    "cov_mat = np.cov(X_train_std.T)\n",
    "\n",
    "# Ensure symmetry in the covariance matrix\n",
    "cov_matrix = (cov_mat + cov_mat.T) / 2.0\n",
    "\n",
    "# Display the rounded covariance matrix\n",
    "cov_matrix.round(1)\n",
    "\n",
    "# Compute the eigenvalues and eigenvectors of the covariance matrix\n",
    "eigen_vals, eigen_vecs = np.linalg.eig(cov_matrix)\n",
    "\n",
    "# Calculate the total variance\n",
    "tot = sum(eigen_vals)\n",
    "\n",
    "# Calculate the explained variance and cumulative explained variance\n",
    "var_exp = [(i / tot) for i in sorted(eigen_vals, reverse=True)]\n",
    "cum_var_exp = np.cumsum(var_exp)\n",
    "\n",
    "# Plot the explained variance and cumulative explained variance\n",
    "plt.bar(range(1, 21), var_exp, alpha=0.5, align='center', label='Variance Explained')\n",
    "plt.step(range(1, 21), cum_var_exp, where='mid', label='Cumulative Explained')\n",
    "plt.xlabel('Principal Component')\n",
    "plt.ylabel('Explained Variance')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### using PCA as inbuilt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca_ = PCA()\n",
    "pca_.fit(X_train_std)\n",
    "\n",
    "Variance_Ratio =  pca_.explained_variance_ratio_\n",
    "cumulative_Variance_Ratio = np.cumsum(Variance_Ratio)\n",
    "plt.plot(cumulative_Variance_Ratio)\n",
    "plt.xlabel('The number of components')\n",
    "plt.ylabel('cumilative explained variance ratio')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " the component having variance percentage  greater than 95% can be considered.so from graphs we can consider 13 components."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<Insert comments>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2\n",
    "- Evaluate the target variable in the `df` object.  \n",
    "- Which metric would you use in evaluating a predictive model. Explain your choice in the markdown cell. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0    744\n",
      "2.0    380\n",
      "1.0    376\n",
      "Name: target, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "y=df['target']\n",
    "print(y.value_counts())\n",
    "y.value_counts().plot.barh()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8900\n",
      "Precision: 0.8903\n",
      "Recall: 0.8900\n",
      "F1 Score: 0.8893\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries for performance metrics and Support Vector Machine (SVM) classifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Create an instance of the Support Vector Machine (SVM) classifier\n",
    "classifier = SVC()\n",
    "\n",
    "# Train the classifier using the training data\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "# Calculate and print various performance metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "print(f'Accuracy: {accuracy:.4f}')\n",
    "print(f'Precision: {precision:.4f}')\n",
    "print(f'Recall: {recall:.4f}')\n",
    "print(f'F1 Score: {f1:.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In evaluating the predictive model for the target variable with three different classes (0, 1, 2) in the `df` object, I would consider using multiclass metrics such as accuracy, precision, recall, and F1 score. These metrics provide a comprehensive understanding of the model's performance across all classes. The choice of a specific metric would depend on the relative importance of correctly predicting each class and the associated costs of false positives and false negatives for each class.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3\n",
    "- Without using PCA, create a logistic regression model using practices discussed in class.  \n",
    "- Which model would you choose? Explain your results in the markdown cells.    \n",
    "- What is the accuracy, precision, and recall for the test data?  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using grdisearch and logistic regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.7033333333333334\n",
      "Precision:  0.7040254342431762\n",
      "Recall:  0.7033333333333334\n",
      "F1 Score:  0.702671996347409\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries for logistic regression, performance metrics, grid search, and data preprocessing\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Create an instance of the Logistic Regression model with a specified random state\n",
    "logistic_model = LogisticRegression(random_state=45)\n",
    "\n",
    "# Define a parameter grid for hyperparameter tuning using GridSearchCV\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10]\n",
    "}\n",
    "\n",
    "# Perform grid search with cross-validation (cv=5) to find the best hyperparameters\n",
    "results = GridSearchCV(logistic_model, param_grid=param_grid, cv=5)\n",
    "results.fit(X_train_std, y_train)\n",
    "\n",
    "# Make predictions on the training and test data using the best estimator from grid search\n",
    "y_train_pred_without_PCA = results.best_estimator_.predict(X_train_std)\n",
    "y_test_pred_without_PCA = results.best_estimator_.predict(X_test_std)\n",
    "\n",
    "# Calculate and print various performance metrics\n",
    "accuracy = accuracy_score(y_test, y_test_pred_without_PCA)\n",
    "precision = precision_score(y_test, y_test_pred_without_PCA, average='weighted')\n",
    "recall = recall_score(y_test, y_test_pred_without_PCA, average='weighted')\n",
    "f1 = f1_score(y_test, y_test_pred_without_PCA, average='weighted')\n",
    "\n",
    "# Display the performance metrics\n",
    "print(\"Accuracy: \", accuracy)\n",
    "print(\"Precision: \", precision)\n",
    "print(\"Recall: \", recall)\n",
    "print(\"F1 Score: \", f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7258333333333333\n"
     ]
    }
   ],
   "source": [
    "# Accuracy on training data without PCA\n",
    "accuracy = accuracy_score(y_train, y_train_pred_without_PCA)\n",
    "print(\"Accuracy on training data without PCA\",accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "using  eigenvalues and eigenvectors and logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6566666666666666\n",
      "Precision: 0.6543828080606774\n",
      "Recall: 0.6566666666666666\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "\n",
    "# Calculate and sort eigenvalue-eigenvector pairs\n",
    "eigen_pairs = [(np.abs(eigen_vals[i]), eigen_vecs[:, i]) for i in range(len(eigen_vals))]\n",
    "eigen_pairs.sort(key=lambda k: k[0], reverse=True)\n",
    "\n",
    "# Set the desired number of principal components\n",
    "number_of_components = 13\n",
    "\n",
    "# Select the top eigenpairs based on eigenvalues\n",
    "selected_eigenvectors = [np.real([pair[1][:, np.newaxis] for pair in eigen_pairs[:number_of_components]])]\n",
    "w = np.hstack(selected_eigenvectors)\n",
    "w = w.reshape(-1, number_of_components)\n",
    "\n",
    "# Project the standardized training and test data onto the selected eigenvectors\n",
    "X_train_pca = X_train_std.dot(w)\n",
    "X_test_pca = X_test_std.dot(w)\n",
    "\n",
    "# Create an instance of the Logistic Regression model\n",
    "model = LogisticRegression(random_state=42)\n",
    "\n",
    "# Train the model using the training data transformed by PCA\n",
    "model.fit(X_train_pca, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = model.predict(X_test_pca)\n",
    "\n",
    "# Calculate and print various performance metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "# Display the performance metrics\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 4\n",
    "- Use PCA within a pipeline to create a logistic regression model using best practices from class.  \n",
    "- Which model performs the best on the training data? Explain your results in markdown cells.  \n",
    "- What is the accuracy, precision, and recall for the test data?\n",
    "- Does this perform better than the original logistic regression model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.6833333333333333\n",
      "Precision:  0.6853002704581328\n",
      "Recall:  0.6833333333333333\n",
      "F1 Score:  0.6826153250773994\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Create a pipeline with scaling, PCA, and Logistic Regression\n",
    "p = Pipeline([\n",
    "    ('scaling', StandardScaler()), \n",
    "    ('pca', PCA()),\n",
    "    ('model', LogisticRegression())\n",
    "])\n",
    "\n",
    "# Define hyperparameters for grid search\n",
    "params = {\n",
    "    'model__C': [0.01, 0.1, 1, 10],\n",
    "    'pca__n_components': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 20]\n",
    "}\n",
    "\n",
    "# Perform grid search with cross-validation (cv=10) to find the best hyperparameters\n",
    "Results = GridSearchCV(p, param_grid=params, scoring='accuracy', cv=10, refit=True)\n",
    "Results = Results.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the training and test data using the best estimator from grid search\n",
    "y_train_pred_with_PCA = results.best_estimator_.predict(X_train)\n",
    "y_test_pred_with_PCA = results.best_estimator_.predict(X_test)\n",
    "\n",
    "# Evaluate the model performance using various metrics\n",
    "accuracy = accuracy_score(y_test, y_test_pred_with_PCA)\n",
    "precision = precision_score(y_test, y_test_pred_with_PCA, average='weighted')\n",
    "recall = recall_score(y_test, y_test_pred_with_PCA, average='weighted')\n",
    "f1 = f1_score(y_test, y_test_pred_with_PCA, average='weighted')\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(\"Accuracy: \", accuracy)\n",
    "print(\"Precision: \", precision)\n",
    "print(\"Recall: \", recall)\n",
    "print(\"F1 Score: \", f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Accuracy on training data with PCA  0.7058333333333333\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_train, y_train_pred_with_PCA)\n",
    "print(\" Accuracy on training data with PCA \",accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### using PCA the  Accuracy on training data for logistic regression is : 70\n",
    "\n",
    "### Without PCA the Accuracy on training data for logistic regression  is : 72"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Without PCA the model performed good compared to  PCA.\n",
    "\n",
    "Without PCA Accuracy: 70 percent\n",
    "using eignevalues and eigenvectors with components : 65 percent\n",
    "with PCA : 68 percent\n",
    "\n",
    "So the algorithm performed better with original logistic regression model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Without using PCA, create a decision tree model using best practices discussed in class.  \n",
    "- Which model performs the best on the training data? Explain your results in the markdown cells.  \n",
    "- What is the accuracy, precision, and recall for the test data?  \n",
    "- Does this perform better than either of the logistic regression models?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In below code i have used standardscalar and decision tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.69\n",
      "Precision:  0.6916977404567766\n",
      "Recall:  0.69\n",
      "F1 Score:  0.6871167159538975\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Create a pipeline with scaling and Decision Tree Classifier\n",
    "p = Pipeline([\n",
    "    ('scaling', StandardScaler()),\n",
    "    ('model', DecisionTreeClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "# Define hyperparameters for grid search\n",
    "params = {\n",
    "    'model__criterion': ['gini', 'entropy'],\n",
    "    'model__max_depth': [None, 10, 20, 30],\n",
    "    'model__min_samples_split': [2, 5, 10],\n",
    "    'model__min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Perform grid search with cross-validation (cv=10) to find the best hyperparameters\n",
    "Results_decision_tree = GridSearchCV(p, param_grid=params, scoring='accuracy', cv=10, refit=True)\n",
    "Results_decision_tree = Results_decision_tree.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the training and test data using the best estimator from grid search\n",
    "y_train_pred_DT = Results_decision_tree.best_estimator_.predict(X_train)\n",
    "y_test_pred_DT = Results_decision_tree.best_estimator_.predict(X_test)\n",
    "\n",
    "# Evaluate the model performance using various metrics\n",
    "accuracy = accuracy_score(y_test, y_test_pred_DT)\n",
    "precision = precision_score(y_test, y_test_pred_DT, average='weighted')\n",
    "recall = recall_score(y_test, y_test_pred_DT, average='weighted')\n",
    "f1 = f1_score(y_test, y_test_pred_DT, average='weighted')\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(\"Accuracy: \", accuracy)\n",
    "print(\"Precision: \", precision)\n",
    "print(\"Recall: \", recall)\n",
    "print(\"F1 Score: \", f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Accuracy on training data without PCA  0.9658333333333333\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_train, y_train_pred_DT)\n",
    "print(\" Accuracy on training data without PCA \",accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decission tree performed way better on training data as it gor 96 percent "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model with decission tree performed good compared to logistic regression.\n",
    "As the accuracy for decission tree is 69\n",
    "logistic is : 68"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 6\n",
    "- Repeat `Question 5` but use PCA.  \n",
    "- Does this perform better than the original Decision Tree or the logistic regression models?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " accuracy  0.73\n",
      " precision 0.7325813845665605\n",
      " recall  0.73\n",
      "Tf1_score  0.7284780155838899\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "p = Pipeline([\n",
    "    ('scaling', StandardScaler()),\n",
    "    ('pca', PCA()),\n",
    "    ('model', DecisionTreeClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "params = {\n",
    "    'model__criterion': ['gini', 'entropy'],\n",
    "    'model__max_depth': [None, 10, 20, 30],\n",
    "    'model__min_samples_split': [2, 5, 10],\n",
    "    'model__min_samples_leaf': [1, 2, 4],\n",
    "    'pca__n_components': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10,11,12,13,14,15, 20]\n",
    "}\n",
    "\n",
    "Results_DT = GridSearchCV(p, param_grid=params, scoring='accuracy', cv=10, refit=True)\n",
    "Results_DT= Results_DT.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_train_pred_DT_PCA = Results_DT.best_estimator_.predict(X_train)\n",
    "\n",
    "y_test_pred_DT_PCA = Results_DT.best_estimator_.predict(X_test)\n",
    "\n",
    "# Evaluate the model performance\n",
    "accuracy = accuracy_score(y_test, y_test_pred_DT_PCA)\n",
    "precision = precision_score(y_test, y_test_pred_DT_PCA, average='weighted')\n",
    "recall = recall_score(y_test, y_test_pred_DT_PCA, average='weighted')\n",
    "f1 = f1_score(y_test, y_test_pred_DT_PCA,average='weighted')\n",
    "\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(\" accuracy \",accuracy)\n",
    "print(\" precision\", precision)\n",
    "print(\" recall \",recall)\n",
    "print(\"Tf1_score \",f1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Accuracy on training data without PCA  0.9658333333333333\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_train, y_train_pred_DT_PCA)\n",
    "print(\" Accuracy on training data with PCA \",accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decission tree performed good compared to logistic regression as it has accuracy with 73."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
